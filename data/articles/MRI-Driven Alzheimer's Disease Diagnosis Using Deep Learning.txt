
TITLE: MRI-Driven Alzheimer’s Disease Diagnosis Using Deep Network Fusion and Optimal Selection of Feature
SOURCE: MRI-Driven Alzheimer's Disease Diagnosis Using Deep Learning.pdf
AUTHOR: Muhammad Umair Ali, Shaik Javeed Hussain, Majdi Khalid, Majed Farrash, Hassan Fareed M. Lahza and Amad Zafar

===== DOCUMENT CONTENT =====

bioengineering Article MRI-Driven Alzheimer’s Disease Diagnosis Using Deep Network Fusion and Optimal Selection of Feature MuhammadUmairAli1,† ,ShaikJaveedHussain2,*,† ,MajdiKhalid3 ,MajedFarrash3, HassanFareedM.Lahza4 andAmadZafar1,* 1 DepartmentofArtificialIntelligenceandRobotics,SejongUniversity,Seoul05006,RepublicofKorea; umair@sejong.ac.kr 2 DepartmentofElectricalandElectronics,GlobalCollegeofEngineeringandTechnology,Muscat112,Oman 3 DepartmentofComputerScienceandArtificialIntelligence,CollegeofComputing,UmmAl-QuraUniversity, Makkah24382,SaudiArabia;mknfiai@uqu.edu.sa(M.K.);mmfarrash@uqu.edu.sa(M.F.) 4 DepartmentofCybersecurity,CollegeofComputingUmmAl-QuraUniversity,Makkah24382,SaudiArabia; hflahza@uqu.edu.sa * Correspondence:s.javeedhussain@gcet.edu.om(S.J.H.);amad@sejong.ac.kr(A.Z.) † Theseauthorscontributedequallytothiswork. Abstract:Alzheimer’sdisease(AD)isadegenerativeneurologicalconditioncharacterizedbycog- nitivedecline,memoryloss,andreducedeverydayfunction,whicheventuallycausesdementia. Symptomsdevelopyearsafterthediseasebegins,makingearlydetectiondifficult.WhileADremains incurable,timelydetectionandprompttreatmentcansubstantiallyslowitsprogression.Thisstudy presentedaframeworkforautomatedADdetectionusingbrainMRIs. Firstly,thedeepnetwork information(i.e.,features)wereextractedusingvariousdeep-learningnetworks.Theinformation extractedfromthebestdeepnetworks(EfficientNet-b0andMobileNet-v2)weremergedusingthe canonicalcorrelationapproach(CCA).TheCCA-basedfusedfeaturesresultedinanenhancedclassi- ficationperformanceof94.7%withalargefeaturevectorsize(i.e.,2532).Toremovetheredundant featuresfromtheCCA-basedfusedfeaturevector,thebinary-enhancedWOAwasutilizedforoptimal featureselection,whichyieldedanaverageaccuracyof98.12±0.52(mean±standarddeviation) withonly953features.Theresultswerecomparedwithotheroptimalfeatureselectiontechniques, Citation:Ali,M.U.;Hussain,S.J.; showingthatthebinary-enhancedWOAresultsarestatisticallysignificant(p<0.01).Theablation Khalid,M.;Farrash,M.;Lahza, studywasalsoperformedtoshowthesignificanceofeachstepoftheproposedmethodology.Fur- H.F.M.;Zafar,A.MRI-Driven thermore,thecomparisonshowsthesuperiorityandhighclassificationperformanceoftheproposed Alzheimer’sDiseaseDiagnosisUsing automatedADdetectionapproach, suggestingthatthehybridapproachmayhelpdoctorswith DeepNetworkFusionandOptimal dementiadetectionandstaging. SelectionofFeature.Bioengineering 2024,11,1076.  Keywords:Alzheimerdisease;dementia;deepfeatures;featurefusion;featureselection;canonical 10.3390/bioengineering11111076 correlationanalysis;optimization;machinelearning AcademicEditor:AndreaCataldo Received:19September2024 Revised:20October2024 1. Introduction Accepted:26October2024 Published:28October2024 Alzheimer’sdisease(AD)isaprogressiveneurodegenerativeconditioncharacterized byirreversiblecognitivedecline,memoryloss,andagradualdeteriorationofbrainfunction, which eventually causes dementia [1]. AD primarily targets brain regions related to cognition,memory,andcommunication,ultimatelyleadingtoaninabilitytoperformdaily Copyright: © 2024 by the authors. tasksindependently. Asthemostcommonformofdementia,ADnecessitatesspecialized Licensee MDPI, Basel, Switzerland. medicalcare. TheglobalburdenofADissubstantialandprojectedtogrowsignificantly, Thisarticleisanopenaccessarticle withaprojected152millionpeopleaffectedby2050. Thispresentsimmenseeconomic, distributed under the terms and healthcare,andsocietalchallenges[2]. Dementiaisarapidlygrowingglobalhealthcrisis, conditionsoftheCreativeCommons affectingapproximatelyonepersonworldwideeverythreeseconds. ADconstitutesthe Attribution(CCBY)license (https:// majorityofdementiacases,representingaround60%ofalldiagnoses[3]. creativecommons.org/licenses/by/ 4.0/). Bioengineering2024,11,1076.  Bioengineering2024,11,1076 2of16 ADislinkedtoseveralstagesofdementia: severedementia,moderatedementia,mild dementia,andmildcognitiveimpairment(MCI).MCIoftenmanifestsasmemorylapses associatedwithagingbutmayprogresstodementiainsomeindividuals. Milddementiais markedbycognitivedifficultiesimpactingdailylife,includingdisorientation,memoryloss, moodchanges,andtroublewithroutinetasks. Moderatedementiapresentsmoresevere symptoms,requiringincreasedsupportfordailyactivities. Individualsmayexperience significantpersonalitychanges,sleepdisturbances,andchallengeswithbasicself-care. In theadvancedstageofseveredementia,individualsexhibitprofoundcognitivedecline,loss ofcommunicationabilities,anddependenceonothersforallaspectsofcare. Currently,noeffectivetreatmentsexisttoceaseorslowtheprogressionofAD,andthe underlyingcausesremainlargelyunknown. MCIrepresentsatransitionalphasebetween normalagingandAD,withindividualsexperiencingMCIatahigherriskofdeveloping thedisease[4]. TheearlydetectionofADiscrucialfordevelopingpreventivestrategies andimprovingtreatmentandcareapproaches. DiagnosingADinvolvesacomprehensiveevaluation,includingthepatient’smedical history,aphysicalexamination,andaneurologicalassessment. Imagingtechniquessuch asMRI,CT,andPETscansareessentialforconfirmingthediagnosis[5]. MRI,inparticular, offersdetailedbrainimages,aidingindetectingstructuralchangesassociatedwithAD[6]. Developingadvancedcomputer-aidedsystemstoanalyzeMRIimagescouldsignificantly improvetheaccuracyandefficiencyofanADdiagnosis[7,8]. Machine-learning techniques, particularly deep learning, have shown promise in enhancingtheaccuracyofidentifyingdifferentdementiasubtypesthroughneuroimag- ing analysis [9]. Traditional machine-learning methods, such as boosting algorithms, random forests, and support vector machines, have been applied to MRI data for AD detection[10-12]. However, these approaches often rely on manually selected brain re- gions, which can be subjective and limited. The pre-selected regions probably do not have all the information needed to comprehend the intricacies of AD because definite MRIbiomarkers forADarestillpoorly understood. Manual selectionisnot onlytime- consumingandlabor-intensive,butitalsohastheriskofsubjectiveerrors. Deep learning, especially convolutional neural networks (CNNs), has emerged as a powerful tool for automatically extracting features from MRI images [13-15]. CNNs have demonstrated superior performance in classifying AD compared to conventional methods [16-18]. Many advantages contribute to its popularity, such as using spatial informationfromnearbypixels,takingimagedatadirectly,andeffectivelyloweringmodel parametersthroughweightsharing,subsampling,etc. ACNNmodeltrainedwithMRI slicesretrievedfeaturesautomatically;itisnolongernecessarytomanuallychoosefeatures duringthelearningphase[19]. Various AD diagnostic CNN models have been reported in the literature [20]. In a study[21],anMRI-and-PET-image-basedCNNmodelhasbeendeveloped.Thismultimodality- basedCNNachieved82.4%accuracyforMCIpatientslaterexposedtoAD.Forthenon- demented class, it yielded a classification rate of 86.3%. Ahmed et al. [22] achieved ac- curaciesof90.05%and85.55%forhealthyandAD,respectively. Apre-trainednetwork, suchasVGG-16, wasalsotrainedforbrainMRIslicesforADdetection[23]. Ityielded a high classification rate of 95.73% for various stages. Similarly, in another study [24], the authors fused the CNN and ensemble-learning models for AD identification. In a recent study, the authors developed a DEMNET to identify and detect several phases of dementia [25]. The DEMNET demonstrated a high classification rate of 95.23% for variousstagesofdementia. Inanotherstudy[26],apre-trainedmodel,suchasAlexNet, wasutilizedtoextractthedeepfeatures,andvariouslinearmachine-learningclassifiers wereusedtoidentifyvariousstagesofdementia. Thestrategyshowedsomepromising resultscomparedtoCNNandhandcraftedmodels. WhilevariousCNNarchitectureshave achievedpromisingresults,challengesremainregardingthemodelcomplexity,training time,andhighclassificationperformance. Bioengineering 2024, 11, x FOR PEER REVIEW 3 of 15 promising results, challenges remain regarding the model complexity, training time, and high classification performance. Bioengineering2024,11,1076 In this study, a hybrid deep feature fusion and optimal feature selection3 oafp16proach is presented for detecting and staging dementia using brain MRIs. Deep features were ex- tracted using various pre-trained deep-learning models. The extracted features were In this study, a hybrid deep feature fusion and optimal feature selection approach merged to form a new feature vector using a canonical correlation analysis (CCA) feature is presented for detecting and staging dementia using brain MRIs. Deep features were fusion approach to enhance the classification performance. Furthermore, the wrapper- extractedusingvariouspre-traineddeep-learningmodels. Theextractedfeatureswere based approach, a binary-enhanced whale optimization algorithm (WOA), is utilized for mergedtoformanewfeaturevectorusingacanonicalcorrelationanalysis(CCA)feature foupstioimnaalp pferaotaucrhet oseelnehctainocne athnedc tlahses irfiecmatoiovnalp eorff orremduanncdea.nFtu frethaeturmreosr.e A, tnh eownlrianpep berr-ain MRI bdaasteadseatp pisr ouascehd,a tboi nvaarlyid-eanthea nthceed pwrohpaloesoepdt iampipzartoioancha.l gAo rcitohmmp(aWriOsoAn), oisf utthileiz epdrofoprosed ap- opprtoimacahl wfeaitthu rveasreiloeuctsi ownraanpdpethr-ebraesmedov aaplporforaedchuensd awnatsf eaaltsuor ecso.nAdnucotneldin. eThbrea rinesMulRtsI are also dcaotmaspetairseuds ewdittho voatlhideart SeOthTeAp raoppposreodacahppesro. ach. Acomparisonoftheproposedapproach withvariouswrapper-basedapproacheswasalsoconducted. Theresultsarealsocompared withotherSOTAapproaches. 2. Materials and Methods 22..1M. Patreorpiaolsseda nAdDM Detehteocdtison and Staging Framework 2.1. ProposedADDetectionandStagingFramework AD is a degenerative brain condition characterized by progressive memory loss and cognAitDivies adedcelginenee. rAatsi vtheeb rmaionscto pnrdeitviaolnencht afroarcmter oizfe ddebmyepnrotigar,e ists icvuermreenmtloyr ylalcoksss aan cdure. MRI cognitivedecline. Asthemostprevalentformofdementia,itcurrentlylacksacure. MRI imaging plays a crucial role in diagnosis by visualizing structural brain abnormalities imaging plays a crucial role in diagnosis by visualizing structural brain abnormalities linked to the disease. Therefore, this study presented an automatic detection and staging linkedtothedisease. Therefore,thisstudypresentedanautomaticdetectionandstaging machine-learning framework for dementia diagnosis. After acquiring the MRIs, the deep machine-learningframeworkfordementiadiagnosis. AfteracquiringtheMRIs,thedeep features were extracted using various pre-trained deep-learning models. In the next step, featureswereextractedusingvariouspre-traineddeep-learningmodels. Inthenextstep, tthheee exxtrtaractcetdedd edeepefpe afetuarteusrwesi twhiathcl aas csilfiacsastifiiocnaaticocnu raacccyuarbaocvye a9b1o%vwe 9er1e%m weregreed museirnggead using a CCCCAAf efaetautruerfeu sfuiosnioanp parpoapcrho.aTchhe. wThraep wperra-bpapseedr-obpatsiemda lofpeatitmuraels efeleacttuiorne mseeltehcotdiofnu rmtheetrhod fur- ethnhera necnehsathnececsla tshsiefi ccalatisosnifircaateti.oTnh eraflteo.w Tchhaer tfloofwthcheaprrto pofo stehde dpermopenotsieadd edteecmtieonntaian ddetection satnagdi nsgtaagpinprgo aacphpirsosahcohw ins sinhoFiwgunr ein1 .Figure 1. Figure1.ADdetectionandstagingusingdeepfeaturefusionandoptimalfeatureselectionapproach. Figure 1. AD detection and staging using deep feature fusion and optimal feature selection ap- proach. Bio Beinoeg Bningioeienenre Bigeniriogni Benen2igeo0gr e22iinnn04geg2 , ei 41nr2,1i0e n1 , e2g1r 14i , 0 2n, x 7 01g 6 21 F24,O 0,x 2R1 F41 ,PO, 1ExR1 EF, P RxOE FRREOE RPVR ER IEPEEREWV ERI EREW VRE IEVWIE W 4 4 o f o 1 f4 6 1o5f 41 5o4 f o1f5 15 2.22..2D.2 D.a2ta.a 2tsDa.e2sta2e.st .taD2ss. a eDttsaa steatsse ts In Inth t iIhsnis stt hIusnitdsu It yndsh,t yiatush,n d saisytonu ,ns doatluinnynd, l oeiyannnd,e la a iodnntnaae oslt idaennstaleeit(n atAd es(aleA zdttahl a(zsetAehaitmles ze(imeAht re(le’Aizsrmh’lDszee hiDarm’tesaai etmsDare’saetsetr (Dat’4s s(a ec4Dtlt aac a(slst4aesa stecs ssle(ea4toss (c sfo4leIa fsmc sI lsomaaefsg sasIe megossef)a s)oIg)mif)es Iisamus)g )sua eeissgsde) eu)dts sio) ste)o dui s st euods e tdo to vavlaidlivadataelitvdetha alvettiehadA elait DdtheAae dtD etehA teetdDh ce Ateti deoDAcent tDieadocn netddti oeeascntntte aidcoagt nniison dtngaa ngsaadtipnan pggdsri t noaasgagptc aipnhagrg.pion Tpagahrc poheaap.d pcrahTopt.ahra coesTha eh.ctd ehiaT s.t hdapTesauhe tbated ls aieicdsttla aysptiesaaut sv bepailtsuii lc bailpsybl iu lcepblayu(lvi hbacatliltylivpac albsyia:ll vea aabivlleaa iblaleb le //(hwttw(phwstt:/.p(k/hwsatt:(g/whp/gwttswl:pew/../skcww:oa//wgm.wkgwa/wlged.wk.gcaalo.tekgam.agcseog/ldetmgs.acl//etodat.mocsaouet/matdrssia/s/etdtttoa5saus5/tter/aotisassuetl/rz5ttsioh5s/u/ttea5orilm5iuzs/rhtae5ilesr5zsti/mh5-ad5ele/izaarmhtslaze-esdhiremaset-t-iedam4rsa-seect-artld-ass4a-sed-tstca--al4soate-afsct-ss-lie-4amots--cfsa4-l-gi-aomcesflss-aai-,smgoasefc-a-socig,mef e-sisasm,ge daaesgc,-e asc, -ac-ac- once1s3sceeNdsso coevednsec smeo1es3ndbs Nee 1odr3on 2oNv 01ne23om 3 1vN)3be. omeNTvrhb oe2eemv0red2 b2m3ee0)trb.2a Te3i2lr)0hs. 2 2eoT30 fdh)2t.ee3 hTt )dai.hs ieTledtsh a daoeitelf asdt tsaoeheitfltia ssta i hodlrsiefas ott ldhaifs siattsehte atddi ssaa eirdtntea a asTltreiaasetsbt eaellitedrs eat 1i erln.dies Ttlieiansdb tTe lieadn b1 iTl.ne a 1bT.al eb 1le. 1. TaTbalbeTl1ea. b1DlT. eeDa t1bTea.lat ieDlabs i1ellase.t b a Da1oibl.eu soDt taaueoibtltn osao luianilntsbl ieooannubAelto iDA nuoDnetd loA aidnntDaaleits naAdeestaD.e Atta .dD sae ttd.a asteats. et. ClaCsCslaelasCsss sleCaesssl saesss es Moderate VeVrVeyre yMrMVyi elMiVdlrdy eiD lrMdye -DiMldei -lDd eD-e- ParPaamraePmtaePrreaastm eraresmt eertse rPsa rametNerosNn-oDnNe-mDoNNneeoo-mnnDn-teD-eeDndmet meeemdenn etMetnedtdie lMdd iDlMMde imDiMllddeeiD mnlDdetee meDndmet eneemdtnMe etdenodMtde edor dMaeteoMr adDtoeeedr maDetreeea mntDetee eDndmt eeemdn etendte d Demented Demmeemnntteeenddmt eemdn etendte d (ND(N) D(N)( N(DND)D ) ) (MI(MD)(IM (DMI)(D IMD)I)D ) (MO(MDO()M D(OM) DO)D ) (MOD) ((VVMM(DVD)M()V D(M)V DM)D ) BrainMRI BraBinra MiBnrR aBMIi rniRam iMIn ai mgRMeIa sRig mIe isam gaesg es images NoN. oof. N SoaofNm .S ooap.fml eoSspfa lmSeaspm lepsl es 256205 602 56205 60 7177 17 7177 17 52 52 52 52 179127 921 79127 92 No.ofSamples 2560 717 52 1792 2.3.2 D.3e. e2Dp.3 e2F.e .epD3a .Fte Dueepraee teF upEer axFett euEraarxtceutt rEriaoexc nEtt rixoatncrt aioctni on 2.3. DeepFeatureExtraction 2.23..31..21C..3 Co.12no.. 3vnC2.ov1.o3lo.un .Cl1tvu.io ootCinlnouovantnoliavolNlun oNtelaiuuole trunNiaoarleanlNu lNa rNlea etNleuw tNerwoauerlort kNawrskl eo(sNtCr w(keCNtsowN Nr(CkoNssrN) sk()NCs N(sC)N NsN) s) CCNNNCN,No, rNCorCN, C CooNNnro ,vnN CoNvo,rN E noCvTEro ,NTCnh,E ovahTnNna,vd nEhNldTeaEl,sne Thdsd, al adehntasaad tndlaiedn asiltn aead s agai n dtrga iadra tii -andgl i -rikalniid ek ga-elrl a iiglkdyareo-yil duiolka-tuleyiat ko lnaeaudn ytl daoiasy uniotsad uaa stinu ssad buan cb idlsscau lsaiabss s scasoul afbsosuacfs rlb aatocirsffilts aiac fisoirscatf ii loafiaflrc tiaiafirlt cifiiacli al nenueruanrleanul nernateewlnut nweroaueroltkr wranskl.eos ntCr.w keCNtsoNw.Nr CkNoesNr .xke NCcsxe.cN lCeesxNlNsac teaNelitxsd cie edaexntlec stine idafltsyeitf niayindttiig nefidyngvie tanvinfragyitro iivfinuoyagsuirn isfvoge afua ervtsaiauo tfrruueieoarsset ufusiesn r aifenatesu na airtnneium sria meiannsg a iieamgn,ne saa ,iu gnsmceu ih,acm sghauae sac,g cshseo u ,ca rocsnsuhr ecn craohessrr nasc seo rrcsno ernrse rs anadndea dnegddae gensed,adsang, enedadsd n,eg dedae fnsgef,edeff acs e,ten ciffavdtinee vecdleyfft lieyveeff celeitlemiylcvi mteieinlvliyianem tlaeeytilsn eiemsatlh tiitemenhsaen intt eehnaeseetd e etnshdf eeo tefh rodnesre pfnesoedperce e ifsdcfiopi crfife occhsr ipafih enscapcd niehfiidccaciirncfi ahrdcfaat ifchnftre adafaniefcttdau rtifarcueefrarta eteffu xeter taxferteat uraecartxteucito trreianeoxc ntetri xoatcnrta icotnio n apapprpaorpaocpaharcepohsaapepcbrsho pybearyisocn habicneclyuhsc ldiebunsiydcn b ligiunyndtg chii lnnetuhcsgdleeu itsnidhengie ni tsnthgeh e teithinhsree eati srhiren cea h iirtrnich th aeetrcihitrctee uhaicrirrtte ucea.hrcrVetictu.ahe rVriceittaoe.u rcuVritsoeuau.lrr aiVesoy .al ueaVrrsyias oel,ruarisoyssu, ue lcsrashsu yl,ca eashsryus eiac,nr shssp u ,iu ancsstuhp ci cunaohtspn cauvionsotn plicuvnuoo-ptn -ucvtoo nc-ovnov-o- tioluntailolu,ntRiaolelu,nL tlRaUiuole,,tn LiaRoaUnnel,dL, a RalUp,en o,RL doaeU lnLpi,nd Uoag op,n, laoidannor gepdli,oun paogsrole,ei odna lugrifneso, e graud,rt s ehaef erodueri s mfeutohdsaree gft deohim ’resf o atfirhemg aeetah t’iusgem re feie’ams/ag itfaenue’gfasroe etf’ur/semir nafetafe/uotainirrtoemufno/riarenemt/fxiioontarrnftamoi oceratnxmitot ireaonaxtn.cito tIreinnaoxc nttethri.xoa etIcnrnta. i coItnnio . nIn. In enthde,t ahefneu dtlehl,yn etadh c eo,ef nun aednl lnf,ey udca lt,c le yofadu n cllfnlaouyeynl clecnytroee drncceot ntelnreadincye teveleacredyt de reldefraet yrarlieaeteurytv rereriereeds vtr rfeefoiedetrrav iitfeemuedvarae etgfdusee raffectoesluara r tfseiuosmsirrfi eaficsomga refta oi iogcrmnl eai am[sc2gsl7aeiafi, gs2ccse8lai a]fitc.siclosTaainhstfiis eoc[iafi2ont7ct ih,a[o22etn8i7ro ],f.[2n u28T 7n][h,.2-2 e7T8 ,]h2.8 eT] .h Teh e daomtheoentrh tfaeoulrtn ehofdlueetahrnmm edfeurae nnfnmtudtseanaonldm fteaaaelmeln CmeetalNneeltnm Naetlles ea nemorlteefse m wano etfeCs nia Ngot shCfN toNas f, a NCnraeN e Ca uwNrNreoe Nainwgrs heea, itrbwgsei,h a ewntsisgee,fuh aingtrcesoht,uon tnrsrsso,e, , nnubaesrin,oau dsbnr oisafa,anc scbts it,fivo aabarcsist tafi,o osaar cnsfnta,o dfcaur tnsano,dccr tast iai,nvo cadantnti sivad.oca nttaii cvotanitv iaotnio n funfcutinocfnutisnof.u cntnsi.co tnios.n s. 2.3.2. DeepFeatureExtractionUsingCNNs 2.3.2T2..h3 D.e22e.C. 3eD2N.p2.e3 N.Fe .D2pe’.sa e FDtepuepeeare retFfpu oeE raFrxemte tuEararatxneuct ctrrEiaeeoxc niEttmri xoaUtpcnrstra iioUncovtgnsieio nCdUngNs bU iCyNnsNguisn sNCginN sC gNNasN lasr gertrainingdataset. Inthisregard, transfeTrhleeTa ChrneNT iCnNhTgNe’sh aNC eplNl ’eoCsr NwNpfoe’sNsrr kmfp’onsear oprmnwfecoarelrfne moidcmreagm npeimacrtoenop vcibrmeeoe divpm tberrodapynv ruboseysfdvei e nurbdrgsye i b naduy glsf a riuarno sgglmiaen rargog tl neraaare r ligtadnreriaorgnim entgrri aa ndtiirnganat idtiannosagietan atdng.s aoI edntttah.a tsIethenarit.s s.te I hIrntnei. s tgIt hnrhaie ristgsdh a,ri rsed gr,ae grda,r d, prtoracnetrssasfe,ntrasr falmeetnrraoas rlfndenesaeirfnlr elngiersi a naltrelrgnlaao irainwnnlgleiosn d awkglfnl soao olrkwlwonoswlon ekwedsn ilgkoseenswd uotgloewee d abltengeod de tb grteraeoe n t -tbrsuoaefs en betrserdrfa eetntdrroasr ffenterrdsoraf rmnfeerrsdo rfoem efndrr eo otf hmdrnoeoe mo mkdnn oaoeomin nwde aolt iedomnd o aagtmnoieno aat titonhnooe a tatrnoh.n o eIaontrnth. h oteIhetnrhri s.te hIrni. s It nh itsh is replartoepcdreospscpr,er oasopbs cmrl,e eoasomc smde,.s eaosAl ,d m isases olumt rdimsaoe itdelnr ieaeasldi ndti rsfeoa odtmirrn afoaeoiinndrne e of dwoins rfies too uhirnse sto ewaun inesoed s aicu snroesedmu -a uernpes adoe-nun drdse eten -ordute st s-treuo[a2ds nt9e rst,dao3fen 0ttrso]r :fat ethnrreas t fnkhesnerf o etkhwrn etloh ekwden lgkoeenwd otglowee da ltnegodoe a gttnhoeoe tatroh n eaornt hoethr er relarteeldart peeldrraoe tplbeardltoee mbpdlr .eop Ambrosl.e sbAmulsem.sm Aue. ms aAs euds msoau mdem oaaemi nd aa ow idmnio tawhmi nitatw hiwn ot iww tchooi ttm hwc optowmo cnopoe omcnnotpems on[pn2tso9e ,nn[32et09sn] ,:[3t 2s0 9][,:23 90,]3:0 ]: dm = A+prob(a) (1) dm d=mA=d+mApd=r+moApb=r(+oaAb)p+( rao p)br (oa b)(a ) (1)(1) (1)(1) where Aand prob(a)denotethefeaturespaceandmarginalprobability. Assumethata tawskhhwerahes ewtrh Aehwe e fhrAaoeenl r ldoeaA w npd A inra ong bpade(rn aoled)bpm( radoep)benr (notdabso)e:(tan ed) ot ethedne eot fhnteeeoa tttfehue aerteht fu eesr apfetea usacprteeua arcsneep d asa pcnmead caa emrng adainn rmdgail am npragraloi rnpgbarianolb bapillar iobptybirl.oai Atbbyais.l sbiAtuiylsmi.st Ayue. ms tAsheuas mstth ueam tt eh atht at a taas kta haska ts aah sttahkase s ht kfhao hsel altfohsow eltlh oifneowg lfli oonelwlgleo miewnlegeinnm egtlese :ne mltesem:n tet r sn=: ts:B +ω (2) whereBandωarethespacelabelandtheotbrj=etcrBti=+vteBωr f=+t ur ωBn=c+ Bt iωo+n ω . d m s andtr s denotethesource(2)(2) (2)(2) domainandtask,whereasdm andtr arethetargetdomainandtask. Thetransferlearning whwerhe ewrBehw e hrBaeen r deaB nωdB a n ωaadrn e dωa t rheω e t at hrs epae a rtsechp eeta t h lcsaeepb aselpacl ebaa eclnela d bal aentlbhd eae lt n hoadben jtdeohc bettjhi evoecebt iojfvebucejnt eifccvutteinio vcfneut i.no fucndtn.i comtdni o.a mnnd. d a mdntd mar n tdadrne ndtdo erttn ed ro etedn eonteo te usedsourceinformationtolearntheconditionalprobabilityforthetarsgets dosmsasin.sThse s ustheeot fhsoseeu tsvhroceetuerh a sredcol eoups morrdecuoae-rtmi cnrdeaa o aiidnmnnoe daadm intnmaad isa noktn da,ad sewn kltds,ha whsetkraahe,ss aekwbrs,e ehwaeedsnhr meerad reseapm ano sddra t mnedtdd rma in ntaadrrtn he dta et rrhlet ie tart ehtr raeeaar rtgttuehae rertte gh dtefeaoot r trmgdaveroatgami nerdita oo aidmunnos daamm intnaade isad nktni a.cad sTan klthd.-a e Tst kah.se kT .h Teh e t t t tt t t t imtraagntirsnafgentrsra falpetenrrpaas rllfnienecsairafnr etlngeiroi a nulnregsnsae iru[dnn3sg i1sen o,du3gu s2 seru]oc.dsuee F srdiciong eusfu oorirncruemefro c2iarenmts fiihoonaonrftmoiw otroansm t liateaoonatn irlo eentnxoa ta r thlnmoee a t plcrhelnoaeen r tcnodhof eitnth ticdhoeoien tnciaboodlnan iptsdairiolico tnpibtoarranolab banpillasr iofbpteybirrl oai-ftlobbyerai al fbitrothinyrleii tnt fythoga refr o-tthra ert-h tea rt-ar- cognecte gdpeott mgudesoatgimin nedgta.o iTdImnmho.a emaTi gnuhae.sei NnTe u .he osTetfe.h suoeesf veu se soerevaf elos refpa vsrleee p-rvtarerelra -apitnlrr aeepdi-rnte rme-adtiron amdeinedole dsmd eh olmasds ohe bdalsese e hlbsnae hsre eanbps e roebernepte eornder tp rieenodpr ttoihenrde tt e lhiidnte e itlrnhiat etetuh rlarietet eul irftroaeetrr u faorteur rfeo rf or varvioaurisvo aumrvsiaeo rdmuiiosec uadmsli- ceimamdl-eiacidmgaiilcna-aiggmli- niaamgpg apianglpgiicnp aagltipi coapanptliispoc aln[i3tcsi1a o,[tn33io2s1 n],.[3s 32F 1][i,.3g3 1Fu2,i]3rg.e2 u F]2.ri e gFs uih2gr oeusw hr2eos ws2ah nsos hwaeonxsw a eamsxn apa melnex paeolmxefa ptmohlfeep t lohbefe a o stbfhic aet sh ibeca bsiacs ic trantrsafentrsr-faletenrraas-rlfnenesarifn-relngeri- anclreognan ircncnoeginpn cctgoe u pncsotci ennupcgseti n Ipumgts aiuInmgsgeian NIggmee ItNam. geaetNg. eeNt.e t. Bioengineering 2024, 11, x FOR PEER REVIEW 5 of 15 Bioengineering2024,11,1076 5of16 Figure2.DeepfeatureextractionusingmodifiedAlexNetusingtransferlearning. Figure 2. Deep feature extraction using modified AlexNet using transfer learning. Inthisstudy,thefrozenweightsofvariouspre-trainednetworksarefine-tunedusing InA thDiMs RstIuimdayg,e st,haen dfrfeoaztuernes wareeiegxthratcst eodf fvroamritoheudse pnsreel-atyrear.inSiexdte enneptrwe-torariknesd amreod fienls,e-tuned using suchasXception,SqueezeNet,ShuffleNet,ResNet-18,ResNet-50,ResNet-101,NASNet- AD MRI images, and features are extracted from the dense layer. Sixteen pre-trained mod- Mobile, MobileNet-v2, Inception-v3, Inception-ResNet-v2, GoogLeNet, GoogLeNet365, els, such as Xception, SqueezeNet, ShuffleNet, ResNet-18, ResNet-50, ResNet-101, EfficientNet-b0,DenseNet-201,DarkNet-53,andDarkNet-19,wereused. NASNet-Mobile, MobileNet-v2, Inception-v3, Inception-ResNet-v2, GoogLeNet, Goog- 2.3.3. CanonicalCorrelationAnalysis(CCA)forFeatureFusion LeNet365, EfficientNet-b0, DenseNet-201, DarkNet-53, and DarkNet-19, were used. This work uses the CCA for deep feature fusion of MRI. The objective is to maxi- mizethecorrelationbetweenfeaturesubsets. Assumetwofeaturesets(f x ∈ R p1 ×b and 2.3.3. Cfa y n∈oRn p i 2 c × a b l) wCiothrrnefleaattuiorens eAtsn,wailtyhspi 1 s a(nCdCp 2 Aa)s fdoimr eFnesiaotnusroef tFheufseiaotunr es,whichcanbe definedasfollows: This work uses the CCA for df e=ep(cid:2) f f1e,af1t,u..r.e, ffnu(cid:3)si(cid:41)on of MRI. The objective is to maximize x x x x (cid:104) (cid:105) (3) ∈ the correlation between featuref y =subf y 1s,eft y 1s,.. ..A, fs y nsume two feature sets ( f x R p×b and 1 f ∈ R ) T w h i e t f h u n n c t f i e on at m u a r y e b s e e d t e s fi , n w ed it a h s fopllow a s: nd p as dimensions of the features, which can y p ×b 1 2 2   be defined as follows: σ =max (cid:0) W x ,W y (cid:1)  W x TC (cid:16) xy W y (cid:17) (4) (WTC W ) WTC W x xx x y yy y f = f1, f1,..., f n Thewithin-covariancematricesma x ybe  de x fine x dasC x x x  ∈  R p1 ×p1 andC xy ∈ Rp1 ×p2. (3) Thefinalcorrelationfunctioncanbeexpf y re = sse  dfa y 1s,fof y l1l,o.w..,s:f y n   (cid:41) C−1C C−1C W = σW xx xy yy yx x x (5) The function may be definCe−d1 Cas Cfo−1llCowWs: = σW yy yx xx xy y y ThefinaltransformedvectorcanbeobtainedusingWEqTuCatioWn(6):  ( ) σ= max W ,W ( x )( xy y ) (4) ∼ x y  WTC W (cid:20) σ (cid:21) WTC W  Z =W x Tσ x,i +W y Tσ y,  i =Wx x TWx y x T σ x x,i y yy y  (6) y,i The within-covariance matrices may be defined as C ∈Rp 1 ×p 1 and C ∈ Rp 1 ×p 2 . The xx xy final correlation function can be expressed as follows: C −1C C −1C W =σW   xx xy yy yx x x  (5) C yy −1C yx C xx −1C xy W y =σW y  The final transformed vector can be obtained using Equation (6): σ   Z  =W Tσ +W Tσ =W TW T  x,i  (6) x x,i y y,i x y σ  y,i CCA enables the integration of multiple characteristics/networks into a unified rep- resentation, capturing complementary information and maximizing the correlation be- tween projected features. Furthermore, it reduces dimensionality while preserving the rel- evant information. Overall, it enhanced the representation of the fused features. Bioengineering2024,11,1076 6of16 CCAenablestheintegrationofmultiplecharacteristics/networksintoaunifiedrepre- sentation,capturingcomplementaryinformationandmaximizingthecorrelationbetween projectedfeatures. Furthermore,itreducesdimensionalitywhilepreservingtherelevant information. Overall,itenhancedtherepresentationofthefusedfeatures. 2.3.4. EnhancedWhaleOptimizationAlgorithm(WOA) TheWOA,developedbyMirjaliliandLewis[33],isapopulation-basedmeta-heuristic algorithmthathasbeeneffectivelyusedtoaddressglobaloptimizationproblemsinvarious areas. Ituseshumpbackwhale’snaturalhuntingbehaviortosolveglobaloptimization challenges. Theycreateabubble-netinaspiralpatterntocapturetheirpreyandswim up to the water’s surface. The WOA utilizes three phases, (i) encircling, (ii) searching, and (iii) spiral bubble-net attacking, to capture the prey in humpback whale’s natural huntingbehavior. (cid:0) (cid:1) LetY(k) = y (k),y (k),...y (k) representthepositionofjthwhaleatiteration j j,1 j,1 j,D k. wherej =1,2,...,NisthepopulationofwhalesinaD-dimensionsearchspace. Y(1)is randomlyinitializedforthefirstandk >1iterationsandY(k)isupdatedusingthreephases: (i)encircling,(ii)searching,and(iii)spiralbubble-netattacking.Duringoptimization,WOA takes into account the probability rate (σ) for eachY(k) for switching among the three j phases,whileitalsoconsiderscoefficientvectorW(k)foreachwhaletoselectencircling j andsearchingforprey,asEquation(7)shows:  (cid:0) (cid:1) (cid:0)(cid:12) (cid:12) (cid:1)  Encirclingprey (cid:0) σ j (k) <0.5 (cid:1) and (cid:0)(cid:12) (cid:12)W j (k) (cid:12) (cid:12) <1 (cid:1) Y j (k+1) = Searchforprey σ j (k) <0.5 and (cid:12)W j (k)(cid:12) ≥1 ,0< σ j (k) <1 (7)  Spiralbubble-netattacking (cid:0) σ(k) ≥0.5 (cid:1) j W(k) =2×w (k)×rand−w (k) (8) j j j where w (k)isthelinearlydecreasedvariablecomputedusingEquation(9): j (cid:18) (cid:19) 2 w (k) =2−k× (9) j MaxIt Equation(10)givestheencirclingpreyphase:  Y(k+1) =Y (k)−W(k)×S(k) j (cid:12) best i (cid:12)  S(t) = (cid:12)C j (k)×Y best (k)−Y j (k)(cid:12) (10) U (k) =2×rand  j where S(k) denotes the distance between the current and the optimal whale position and C (k) is the coefficient vector at iteration k. The search for prey phase is given in j Equation(11): (cid:27) Y(k+1) =Y (k)−W(k)×S(k) j (cid:12) rnd j (cid:12) (11) S(k) = (cid:12)C j (k)×Y rnd (k)−Y j (k)(cid:12) Finally,thethirdphase(i.e.,thespiralbubble-netattacking)isgivenasEquation(12), wherecisthelogarithmicspiralshape: Y(k+1) = S′(k)×expcl×cos(2πl)+Y (k) (cid:27) j S′(k) = (cid:12) (cid:12)Y best (k)−Y j (k) (cid:12) (cid:12) best ,−1≤ l ≤1 (12) Despitebeingawidelyusedoptimizationtechnique,theWOAstillsuffersfromearly convergence, poor population diversity causing insufficient solutions, and a mismatch oflocalandglobalsearchstrategiesfurtheraddressedinitsenhancedWOAandbinary E-WOAvariantsforfeatureselection. Bioengineering2024,11,1076 7of16 To further enhance the performance of conventional WOA, Nadimi-Shahraki and coworkers introduced a pooling mechanism and three efficient search techniques (i.e., migrating,preferentialselection,andenrichedsurroundingprey). Furthermore,advanced searchtechniqueswerealsoincorporated. Inpoolingmechanism,attheendofeachiteration,thepoolmatrix(P(1),P(2),...,P(m)) havingmembersP = P(1),P(2),...,P(m)arecomputedusingEquation(13): j j j i P(k) = B (k)×Y (k)×B (k)+Y (k) (13) j j brnd j worst where Y (k) are randomly computed to generate random positions around Y (k). brnd best Y (k)representstheworstwhaleatthecurrentiteration,whereasB (k)andB (k)are worst j j therandombinaryvectorsandtheirreversebinaryvector. Inordertofosterpopulation diversity,thepoolingmechanismusesacrossoveroperatortocombinetheworstsolution withthebestone. Whenthepool’ssizeisreached,anewsolutionisreplacedbyanexisting poolmember. ThemigratingsearchmethoddividesagroupofwhalesatrandomusingEquation(14) to allow them to explore previously unexplored places and increase their exploration. Furthermore,thisseparationisprojectedtoimprovepopulationdiversity,loweringtherisk ofbecominglockedinlocaloptima:  Y(k+1) =Y (k)−Y (k) j rnd brnd  Y (k) =rand×(δ −δ )+δ (14) rnd max min min Y (k) =rand(δ −δ )+δ  brnd best_max best_min best_min whereδ andδ aretheupperandlowerboundsofY (k). best_max best_min best Finally,thepreferentialselectionstrategycomputedusingEquation(15)furtheren- hancesthesearch-for-preyapproach: Y(k+1) =Y(k)+W(k)×(U (k)×P (t)−P (t)) (15) j j j k rnd1 rnd2 whereP (t)andP (t)arerandomlyselectedfrompoolmatrix. rnd1 rnd2 Theencirclingpreymethodisfurtherenhancedusingthefollowingequation: Y(k+1) =Y (k)−W(k)×S′(k) (cid:27) S′ j (k) = (cid:12) (cid:12)C j (k) be × st Y best (k) j −P rnd3 (k) (cid:12) (cid:12) (16) whereP (t)canberandomlyselectedfromthepoolmatrix. rnd3 Furthermore,fortheeffectiveselectionoffeatures,Nadimi-Shahrakietal.[34]also proposedthebinaryversionoftheenhancedvariantofWOA(Algorithm1). Thebinary versionisespeciallyusefulfordeterminingthemostimportantoroptimalfeaturesassoci- atedwithspecificmedicaldisorders. Thesebinaryoptimizationfeatureselectionmethods areusefulinmedicalapplicationsbecausetheyimprovediagnosticaccuracyandefficiency byfocusingonthemostimportantcharacteristicsorvariables. Toevaluatetheselectedfeature,thek-nearestneighbor(kNN)-basedfitnessfunction isgivenbelow: (cid:18) (cid:19) (cid:18) (cid:19) Imageswhicharecorrectlyclassified f F(X) =0.99 1− +(0.01) SL (17) Totalimages f FL where f and f arethetotalnumberoffeaturesandtheselectednumberoffeatures[35]. FL SL Finally, the results of the classifier were analyzed using the confusion matrix, which includedthetruepositiverate(TPR),falsenegativerate(FNR),positivepredictivevalue (PPV),andfalsediscoveryrate(FDR). Bioengineering2024,11,1076 8of16 Algorithm1:Pseudo-codeofbinary-enhancedWOA[34]. 1.GeneratearandompopulationofNwhalesusing (cid:26) 1rand≥0.5 bk = , j=1,2,...,Nandi=1,2,...,D j,i 0rand<0.5 2.InitializeK(maximumiterations) 3.Evaluatethesolutionofthepopulationusingthefitnessfunction 4.DetermineY best 5.Setk=1 6.while(k<K)do 7.RandomlyselectaportionPoftheNpopulation 8.DetermineYk+1(mitigatingsearchstrategy) j∈p 9.ifkisnotinPthen 10.ComputeσkandWk j j 11.if(σk<0.5)then j 12.ifWk<0.5then j 13.ComputeYk+1using(10)forenrichedencirclingpreystrategy j 14.elseifAt>0.5then i 15.ComputeYk+1using(9)forapreferentialselectionstrategy j 16.endif 17.elseif(σk>0.5)then j 18.ComputeYk+1using(6)forthespiralbubble-netattackingstrategy j 19.endif  (cid:16) (cid:17) 1U yk ≥rand(0,1) 20.Transformcontinuoussearchspacetobinaryusingbt = (cid:16) ij (cid:17) i,j 0U yk <rand(0,1) ij 21.Evaluatethefitnessvalueforeachsolution (cid:110) (cid:111) 22.UpdateYk+1usingthepositionwithlowerfitnessvaluefrom Yk,Yk+1 j j j 23.endif 24.UpdateY best 25.k=k+1 26.endwhile 3. Results Inthisstudy,allthesimulationandanalysisareperformedonMATLAB2023arun- ningona64-bitWindows11personalcomputerwiththefollowingspecifications: 12th Generation,Corei7,1TBSSD,NVIDIAGeForceRTX3050,and32GBRAM.Thedataset wasrandomlydividedintoa80:20ratioformodeltrainingandtesting. Augmentationwas alsocarriedouttobalancethedatasetat1000samplesperclass. To check the performance of various commonly used pre-trained models, such as DenseNet-201,EfficientNet-b0,GoogleNet,Inception-v3,andResNet50,theyweretrained toclassifythebrainMRIsintosubclasses. ThefindingsarelistedinTable2. Table2.Resultsofvariouspre-trainedmodelsforAlzheimer’sDataset. Training Training Validation Validation Training CNNs Accuracy(%) Loss Accuracy(%) Loss Time DenseNet-201 100 1.4×10−04 93.93 0.2152 1062min20s EfficientNet-b0 100 2.8×10−03 90.32 0.3030 329min45s GoogleNet 100 3.6×10−04 92.57 0.3584 40min30s Inception-v3 100 4.3×10−04 84.84 0.5598 435min47s ResNet50 100 1.9×10−04 88.95 0.3938 299min40s MobileNet-v2 100 3.2×10−04 91.02 0.3818 195min55s Bioengineering 2024, 11, x FOR PEER REVIEW 9 of 15 Table 2. Results of various pre-trained models for Alzheimer’s Dataset. Training Accuracy Validation Accu- CNNs Training Loss Validation Loss Training Time (%) racy (%) DenseNet-201 100 1.4 × 10−04 93.93 0.2152 1062 min 20 s EfficientNet-b0 100 2.8 × 10−03 90.32 0.3030 329 min 45 s GoogleNet 100 3.6 × 10−04 92.57 0.3584 40 min 30 s Inception-v3 100 4.3 × 10−04 84.84 0.5598 435 min 47 s ResNet50 100 1.9 × 10−04 88.95 0.3938 299 min 40 s MobileNet-v2 100 3.2 × 10−04 91.02 0.3818 195 min 55 s Bioengineering2024,11,1076 9of16 The results presented in Table 2 show that DenseNet-201 has the best classification accuracy of 93.93% for AD detection, but the model took almost 17 h to train. In contrast, TheresultspresentedinTable2showthatDenseNet-201hasthebestclassification GoogalcecNureatc yshoofw93s.9 a3% refaorsoAnDadbelete cctliaosns,ibfiuctatthieonm opdeerlftooromkaalnmcoes t(9127.h57to%tr)a wini.tIhn mcoinntriamsta,l training time G(aolomgloesNte 4ts1h omwisna).r eTaoso rneadblueccela stshifiec tartiaoinnpinegrf otrimmaen,c eth(9e2 .d57e%ep)w fietahtmurineism waletrraei neinxgtracted for time(almost41min). Toreducethetrainingtime, thedeepfeatureswereextractedfor various pre-trained models, and a conventional/linear classifier was used for classifica- variouspre-trainedmodels,andaconventional/linearclassifierwasusedforclassification. tion. The results are presented in Figure 3, which shows that the accuracy achieved using TheresultsarepresentedinFigure3,whichshowsthattheaccuracyachievedusingthe the deep features is similar to that of pre-trained networks shown in Table 2 but with a deepfeaturesissimilartothatofpre-trainednetworksshowninTable2butwithareduced reducceodm pcuotmatpiounatalttiimone.al time. Figure 3. Classification performance comparison of various deep features for AD detection. Figure3.ClassificationperformancecomparisonofvariousdeepfeaturesforADdetection. AfteAr fatenraalnyazliynzgin gthteh erreessuullttss sshhoowwnnin iFni gFuirgeu3r,ei t3c,a nit bceacno nbcelu cdoendctlhuadttehde mthoadte tlshe models trainedonEfficientNet-b0andMobileNet-v2deepfeatures(1280foreach)showthehighest trained on EfficientNet-b0 and MobileNet-v2 deep features (1280 for each) show the high- classification accuracy of 91.64 ± 0.99% and 91.08 ± 1.62% for ten runs. To enhance est classification accuracy of 91.64 ± 0.99% and 91.08 ± 1.62% for ten runs. To enhance classification,theCCAfeaturefusionapproachwasappliedtomergethedeepfeatures classiofifcbaottihomn,o tdheels C. ACfAter ftehaattu,vraer fiouussiofena tauprepsreoleaccthio nwaapsp aropapclhieesdw teor emuesregdet othreed duceeetph efeatures of both fmeaotudreelssi.z Aeoftfethr ethCaCtA, -vbaarsieodufus sfeedafteuartuer seevleeccttoiro,nan adpthperoreascuhltessa rweperrees eunsteedd itnoT raebdleu3ce the fea- andFigure4. ture size of the CCA-based fused feature vector, and the results are presented in Table 3 and Figure 4. Bioengineering2024,11,1076 10of16 Table3.ClassificationaccuracyofapproachestosubclassifythebrainMRIimagesforADdetection(10runs). CCA+FeatureSelectionApproaches CCA-Based Generalized Marine Manta-Ray HenryGas PoorAnd No.ofRuns Fused Normal SlimeMold Equilibrium AtomSearch Pathfinder Predator Foraging Solubility Rich WOA Features Distribution Algorithm Optimizer Optimization Algorithm Algorithm Optimization Optimization Optimization Optimization 1 95.21 97.17 97.17 96.00 97.17 97.17 96.09 95.80 96.68 97.46 98.05 2 95.12 97.17 96.88 95.61 97.36 96.68 96.78 95.70 96.00 96.88 97.95 3 95.51 96.88 96.39 94.92 96.09 96.58 96.29 95.41 96.09 96.58 96.97 4 93.75 95.70 95.61 93.95 95.21 95.90 94.92 94.53 94.92 95.70 96.68 5 94.04 96.29 96.00 94.63 95.90 96.29 95.02 94.63 95.12 95.70 96.68 6 95.90 97.46 96.88 96.19 96.97 97.36 96.97 96.39 97.07 97.36 98.24 7 94.14 96.39 95.90 94.63 96.29 95.80 95.61 95.02 95.41 95.90 97.17 8 94.43 96.78 96.00 94.82 96.19 96.29 96.09 95.41 96.00 96.29 96.97 9 93.65 96.58 95.41 94.43 95.70 95.90 94.82 94.73 95.12 95.70 96.78 10 95.21 96.78 96.78 95.02 96.29 96.88 96.00 95.41 96.19 96.39 97.27 mean±std 94.7±0.79 96.72±0.51 96.3±0.6 95.02±0.71 96.32±0.67 96.48±0.54 95.86±0.75 95.3±0.58 95.86±0.71 96.4±0.67 97.28±0.59 Bioengineering 2024, 11, x FOR PEER REVIEW 10 of 15 Table 3. Classification accuracy of approaches to subclassify the brain MRI images for AD detection (10 runs). CCA + Feature Selection Approaches CCA- General- Manta-Ray Henry Gas Path- No. of Based Marine ized Nor- Slime Equilib- Atom Poor And Foraging Solubility finder Runs Fused Predator mal Distri- Mold Al- rium Op- Search Op- Rich Opti- WOA Optimiza- Optimiza- Algo- Features Algorithmbution Op- gorithm timizer timization mization tion tion rithm timization 1 95.21 97.17 97.17 96.00 97.17 97.17 96.09 95.80 96.68 97.46 98.05 2 95.12 97.17 96.88 95.61 97.36 96.68 96.78 95.70 96.00 96.88 97.95 3 95.51 96.88 96.39 94.92 96.09 96.58 96.29 95.41 96.09 96.58 96.97 4 93.75 95.70 95.61 93.95 95.21 95.90 94.92 94.53 94.92 95.70 96.68 5 94.04 96.29 96.00 94.63 95.90 96.29 95.02 94.63 95.12 95.70 96.68 6 95.90 97.46 96.88 96.19 96.97 97.36 96.97 96.39 97.07 97.36 98.24 7 94.14 96.39 95.90 94.63 96.29 95.80 95.61 95.02 95.41 95.90 97.17 8 94.43 96.78 96.00 94.82 96.19 96.29 96.09 95.41 96.00 96.29 96.97 9 93.65 96.58 95.41 94.43 95.70 95.90 94.82 94.73 95.12 95.70 96.78 10 95.21 96.78 96.78 95.02 96.29 96.88 96.00 95.41 96.19 96.39 97.27 97.28 ± mean ± 94.7 ± 0.79 96.72 ± 95.02 ± 96.32 ± 95.86 ± 96.3 ± 0.6 96.48 ± 0.54 95.86 ± 0.75 95.3 ± 0.58 96.4 ± 0.67 0.59 std Bioengineerin0g.52012 4,11,1076 0.71 0.67 0.71 11of16 (a) (b) Figure4.(a)NumberoffeaturesusedtosubclassifybrainMRIimages;(b)processingtimetakenby eachapproach. Compared to all, the WOA has shown the highest classification performance of 97.28±0.59%withanaverageof985features. Italsotooklessthanoneandahalfminutes to find the optimal feature and train the model, as shown in Figure 4b. Therefore, the binary-enhanced variant of WOA is applied to increase the classification performance further,andtheresultsarepresentedinFigure5. Finally,theresultsoftheablationstudy arepresentedinFigure6. Bioengineering 2024, 11, x FOR PEER REVIEW 11 of 15 Bioengineering 2024, 11, x FOR PEER REVIEW 11 of 15 Figure 4. (a) Number of features used to subclassify brain MRI images; (b) processing time taken by each approach. Figure 4. (a) Number of features used to subclassify brain MRI images; (b) processing time taken by each approach. Compared to all, the WOA has shown the highest classification performance of 97.28 ± 0.59% with an average of 985 features. It also took less than one and a half minutes to Compared to all, the WOA has shown the highest classification performance of 97.28 find the optimal feature and train the model, as shown in Figure 4b. Therefore, the binary- ± 0.59% with an average of 985 features. It also took less than one and a half minutes to enhanced variant of WOA is applied to increase the classification performance further, find the optimal feature and train the model, as shown in Figure 4b. Therefore, the binary- and the results are presented in Figure 5. Finally, the results of the ablation study are pre- enhanced variant of WOA is applied to increase the classification performance further, sented in Figure 6. and the results are presented in Figure 5. Finally, the results of the ablation study are pre- sented in Figure 6. Bioengineering2024,11,1076 12of16 Figure 5. Result for dementia identification and staging using a hybrid deep feature fusion and op- timal feature selection approach. Figure5. Resultfordementiaidentificationandstagingusingahybriddeepfeaturefusionand Figure 5. Result for dementia identification and staging using a hybrid deep feature fusion and op- optimalfeatureselectionapproach. timal feature selection approach. Figure6. AblationstudyresultsforADdetection(fortenruns). MN-v2, MobileNet-v2; EN-b0, FigEuffircei e6n.t NAebt-bla0;tiCoCnA s,tcuandoyni craelscuorlrtesla ftoiorn AanDal ydsies;teWcOtiAo,nw (hfaoler otpetnim rizuantiso)n. aMlgoNrit-hvm2;, bM-EoWbOiAle,Net -v2; EN-b0, Effi- cienbitnNareyt-e-nbh0a;n CceCdAwh, acleaonpotinmicizaalt iocnoralrgeolraitthimon. analysis; WOA, whale optimization algorithm; b-EWOA, Figure 6. Ablation study results for AD detection (for ten runs). MN-v2, MobileNet-v2; EN-b0, Effi- binary-enhanced whale optimization algorithm. 4. Discussion cientNet-b0; CCA, canonical correlation analysis; WOA, whale optimization algorithm; b-EWOA, Diagnosing AD involves a multifaceted approach. A detailed examination of neu- binary-enhanced whale optimization algorithm. 4. Droiimscaugisnsgiodant a,particularlybrainMRIs,playsavitalroleinunderstandingthedisease progressionanddeterminingappropriatetreatmentstrategies. However,distinguishingbe- Diagnosing AD involves a multifaceted approach. A detailed examination of neu- 4.t wDeiesnchuesalsthioynan ddiseasedbraintissuerequiresspecializedknowledgeandexpertise. The roimmaanguainlagn adlyastisa,p rpoacerstsiccaunlabreltyim be-rcaoinns uMmiRngI,sp, optelantyiasl lya hvinitdaelr inroglper oimnp utdnidagenrosstiasnding the disease Diagnosing AD involves a multifaceted approach. A detailed examination of neu- proangdrecasrsei.oTnh earenfodre d,aeutteormmatiendiAnDg daeptepctrioonptreicahnteiq utreesaartemuergnetn tslytrnaeteedgedietso.s tHreoamwlienveer, distinguishing roimaging data, particularly brain MRIs, plays a vital role in understanding the disease progression and determining appropriate treatment strategies. However, distinguishing Bioengineering2024,11,1076 13of16 diagnosis,improveaccuracy,andenhancepatientcare. Thisresearchinvestigatesahybrid frameworkcombiningdeepfeatures,canonicalcorrelationanalysis,andoptimalfeature selectiontoimprovetheaccuracyofautomatedADdetectionusingbrainMRIs. Thisstudy aimstocontributetoaccurateearlyADdetectionbycomputer-aidedsystems. Initially,sixteenpre-traineddeep-learningmodelsrangingfromsimpletocomplex were selected for deep feature extraction. In our study, the accuracy-driven selection providesastraightforwardandeffectivewaytoidentifypre-trainednetworks’suitabledeep features. EfficientNet-b0’sandMobileNet-v2’sdeepfeatureswerechosen(Figure3),and featurefusionwascarriedoutusingCCA.CCAreducesdimensionalitywhilepreserving therelevantinformation. Overall,itenhancedtherepresentationofthefusedfeatures. Itis evidentfromTable3thattheclassificationaccuracyofsubclassifyingthedementiaclassis increasedbyalmost3%comparedtosimplesingle-modeldeepfeatures. However,italso increasesthefeaturevectorsizeto2532,asshowninFigure4a. Therefore,variouswrapper- based methods were applied to further reduce the feature vector size and enhance the classificationperformance. Alltheapproachesperformedbetterwithsmallfeaturevector sizesthanthefusedfeaturevectors(seeTable3andFigure4a). Comparedtoall,theWOA hasshownthehighestclassificationperformancewiththeleastfeatures. Therefore,the binary-enhancedWOAwasfurtherimplemented,increasingtheclassificationperformance to98.25%andreducingthemisclassificationratecomparedtotheconventionalWOA.It alsoreducesthefeaturevectorsizeto953featureswithonlyan87saverageprocessing time. Thebinary-enhancedWOAdemonstratessuperiorfeaturedetectionandselection capabilitiesowingtoitseffectivesearchmethodology. ConventionalWOAreliessolely onobjectivefunctions,whichmayoverlookcomplexitiesintheADdataset,potentially selectingsuboptimalfeatures. Thislimitationcancompromiseclassificationaccuracy. In contrast,thebinary-enhancedWOAemploysamultifacetedfeatureselectionapproach, combiningobjectivefunctionswiththreeadvancedsearchtechniques. Thishybridstrategy enables an exhaustive exploration of the feature space, uncovering a diverse array of optimal features. As discussed in Section 2.3.4, this enhanced search capability allows the binary-enhanced WOA to outperform the conventional WOA, yielding improved classificationresults. Theablationstudywasalsoperformedtoseetheeffectofeachphaseoftheproposed methodology (Figure 6). The t-test was performed to check the statistical significance of each step, and it was observed that each step of the proposed approach statistically enhancedtheclassificationaccuracywithp<0.01. Thisshowsthattheadditionofeach stepisstatisticallysignificant,andtheresultsarereliable. Table4comparestheoutcomes ofthepresentedhybridapproachwithotherSOTAmethods. Table4.PerformancecomparisonofvariousSOTAapproacheswithaproposedhybridapproach. Study Alzheimer’sDataset Shuklaetal.[36] 94 Mohammedetal.[37] 94.8 Muruganetal.[25] 95.23 Acharyaetal.[38] 95.70 El-Latifetal.[39] 95.93 Loddoetal.[40] 97.71 98.25(maximum) Proposedhybridapproach 98.12±0.52(mean±standarddeviation) Table4demonstratesthatthepresentedhybridapproachhasthebestclassification performancecomparedtootherSOTAapproaches. Theseresultsemphasizetheeffective- nessofthepresentedhybridizedapproachinaccuratelyandefficientlyhandlingdementia detectionandstaging,highlightingitspotentialasastrongsolutionforADdetection. Bioengineering2024,11,1076 14of16 This study’s findings are based on a single dataset, and future work will focus on assessingthemethodology’sbroaderapplicabilityacrossvarieddatasets. Furthermore, thisstudyfocusesexclusivelyonMRIdata,whereasfutureinvestigationswillexplorethe potentialofmultimodaldataintegrationtoenhanceADdetection. Finally,thismanuscript consideredasimpleaccuracy-basednetworkselectionstrategy. Futureresearchshouldcon- siderincorporatingdiverseevaluationmetricsanddynamicstrategiestofurtherimprove thenetworkselectionprocessandsupportreal-time/onlineimplementations. 5. Conclusions ADisawidespreadanddebilitatingneurologicalcondition.Itsignificantlydiminishes thequalityoflifeforthoseaffected,impactingnotonlythepatientsthemselvesbutalso theirfamiliesandsocietyatlarge. AtimelydiagnosisiscrucialforeffectivelymanagingAD andminimizingitssocioeconomicimpact. Thisstudypresentedanautomateddementia detection and staging approach using brain MRIs. First, various pre-trained networks wereutilizedtocomputethedeepfeatures. ThemodelstrainedwithEfficientNet-b0and MobileNet-v2deepfeatures(1280foreach)showaccuraciesof91.64%and91.08%,respec- tively. Afterthat,canonicalcorrelationanalysiswasperformedforfeatureconcatenation. Anaccuracyof94.7%wasobtainedwith2532features. Furthermore,thebinary-enhanced WOAwasutilizedfortheoptimalselectionoffeatures,resultingina98.25%classification ratewithoptimalfeatures(i.e.,953). Theresultsobtainedwerecomparedwithotherfea- tureselectiontechniques,showingthatthebinary-enhancedWOAresultsarestatistically significant(p<0.01). Theseresultsdemonstratethesuperiorperformanceoftheproposed hybridapproachindementiadetectionandstaging,showcasingitspotentialasareliable toolforAlzheimer’sdiseasedetection. AuthorContributions:Conceptualization,M.U.A.andS.J.H.;formalanalysis,M.F.;methodology, M.U.A.andS.J.H.;projectadministration,A.Z.;software,H.F.M.L.;supervision,A.Z.;validation, M.K.; visualization, A.Z.; writing-original draft, M.U.A. and S.J.H.; writing-review and edit- ing,M.K.,M.F.,H.F.M.L.andA.Z.Allauthorshavereadandagreedtothepublishedversionof themanuscript. Funding:WeacknowledgetheGlobalcollegeofEngineeringandTechnology,Muscatforfunding thisresearchunderaninternalfundinggrant. InstitutionalReviewBoardStatement:Notapplicable. InformedConsentStatement:Notapplicable. DataAvailabilityStatement:TheoriginaldatapresentedinthestudyareopenlyavailableinKaggle at 13November2023). ConflictsofInterest:Theauthorsdeclarenoconflictsofinterest. References 1. Ulep,M.G.;Saraon,S.K.;McLea,S.Alzheimerdisease.J.NursePract.2018,14,129-135.[CrossRef] 2. Salvatore,C.;Cerasa,A.;Battista,P.;Gilardi,M.C.;Quattrone,A.;Castiglioni,I.Magneticresonanceimagingbiomarkersforthe earlydiagnosisofAlzheimer’sdisease:Amachinelearningapproach.Front.Neurosci.2015,9,307.[CrossRef] 3. Patterson,C.WorldAlzheimerReport2018.2018.Availableonline: 2018/(accessedon4February2024). 4. Liu,S.;Liu,S.;Cai,W.;Pujol,S.;Kikinis,R.;Feng,D.EarlydiagnosisofAlzheimer’sdiseasewithdeeplearning.InProceedingsof the2014IEEE11thInternationalSymposiumonBiomedicalImaging(ISBI),Beijing,China,29April-2May2014;pp.1015-1018. 5. Sabbagh,M.N.;Lue,L.-F.;Fayard,D.;Shi,J.IncreasingPrecisionofClinicalDiagnosisofAlzheimer’sDiseaseUsingaCombined AlgorithmIncorporatingClinicalandNovelBiomarkerData.Neurol.Ther.2017,6,83-95.[CrossRef][PubMed] 6. Moser,E.;Stadlbauer,A.;Windischberger,C.;Quick,H.H.;Ladd,M.E.Magneticresonanceimagingmethodology.Eur.J.Nucl. Med.Mol.Imaging2009,36,30-41.[CrossRef][PubMed] 7. Noor,M.B.T.;Zenia,N.Z.;Kaiser,M.S.;Mamun,S.A.;Mahmud,M.Applicationofdeeplearningindetectingneurologicaldisor- dersfrommagneticresonanceimages:AsurveyonthedetectionofAlzheimer’sdisease,Parkinson’sdiseaseandschizophrenia. BrainInform.2020,7,11.[CrossRef][PubMed] Bioengineering2024,11,1076 15of16 8. Baratti,C.;Barkhof,F.;Hoogenraad,F.;Valk,J.Partiallysaturatedfluidattenuatedinversionrecovery(FLAIR)sequencesin multiplesclerosis:ComparisonwithfullyrelaxedFLAIRandconventionalspin-echo.Magn.Reson.Imaging1995,13,513-521. [CrossRef] 9. Mateos-Pérez,J.M.;Dadar,M.;Lacalle-Aurioles,M.;Iturria-Medina,Y.;Zeighami,Y.;Evans,A.C.Structuralneuroimagingas clinicalpredictor:Areviewofmachinelearningapplications.NeuroImageClin.2018,20,506-522.[CrossRef] 10. Rabeh,A.B.;Benzarti,F.;Amiri,H.DiagnosisofAlzheimerDiseasesinEarlyStepUsingSVM(SupportVectorMachine). In Proceedingsofthe201613thInternationalConferenceonComputerGraphics,ImagingandVisualization(CGiV),BeniMellal, Morocco,29March-1April2016;pp.364-367. 11. Tripoliti, E.E.; Fotiadis, D.I.; Argyropoulou, M. A supervised method to assist the diagnosis and monitor progression of Alzheimer’sdiseaseusingdatafromanfMRIexperiment.Artif.Intell.Med.2011,53,35-45.[CrossRef] 12. Hinrichs,C.;Singh,V.;Mukherjee,L.;Xu,G.;Chung,M.K.;Johnson,S.C.SpatiallyaugmentedLPboostingforADclassification withevaluationsontheADNIdataset.NeuroImage2009,48,138-149.[CrossRef] 13. Hinton,G.E.Deepbeliefnetworks.Scholarpedia2009,4,5947.[CrossRef] 14. Vincent,P.;Larochelle,H.;Lajoie,I.;Bengio,Y.;Manzagol,P.-A.;Bottou,L.Stackeddenoisingautoencoders:Learninguseful representationsinadeepnetworkwithalocaldenoisingcriterion.J.Mach.Learn.Res.2010,11,3371-3408. 15. Rawat,W.;Wang,Z.DeepConvolutionalNeuralNetworksforImageClassification:AComprehensiveReview.NeuralComput. 2017,29,2352-2449.[CrossRef] 16. Ali,M.U.;Kallu,K.D.;Masood,H.;Tahir,U.;Gopi,C.V.V.M.;Zafar,A.;Lee,S.W.ACNN-BasedChestInfectionDiagnosticModel: AMultistageMulticlassIsolatedandDevelopedTransferLearningFramework.Int.J.Intell.Syst.2023,2023,6850772.[CrossRef] 17. Alanazi,M.F.;Ali,M.U.;Hussain,S.J.;Zafar,A.;Mohatram,M.;Irfan,M.;AlRuwaili,R.;Alruwaili,M.;Ali,N.H.;Albarrak, A.M.BrainTumor/MassClassificationFrameworkUsingMagnetic-Resonance-Imaging-BasedIsolatedandDevelopedTransfer Deep-LearningModel.Sensors2022,22,372.[CrossRef] 18. Almalki,Y.E.;Ali,M.U.;Kallu,K.D.;Masud,M.;Zafar,A.;Alduraibi,S.K.;Irfan,M.;Basha,M.A.A.;Alshamrani,H.A.;Alduraibi, A.K.;etal.IsolatedConvolutional-Neural-Network-BasedDeep-FeatureExtractionforBrainTumorClassificationUsingShallow Classifier.Diagnostics2022,12,1793.[CrossRef][PubMed] 19. Lin,W.;Tong,T.;Gao,Q.;Guo,D.;Du,X.;Yang,Y.;Guo,G.;Xiao,M.;Du,M.;Qu,X.;etal.ConvolutionalNeuralNetworks-Based MRIImageAnalysisfortheAlzheimer’sDiseasePredictionFromMildCognitiveImpairment. Front. Neurosci. 2018,12,777. [CrossRef] 20. Wen,J.;Thibeau-Sutre,E.;Diaz-Melo,M.;Samper-González,J.;Routier,A.;Bottani,S.;Dormont,D.;Durrleman,S.;Burgos,N.; Colliot,O.ConvolutionalneuralnetworksforclassificationofAlzheimer’sdisease:Overviewandreproducibleevaluation.Med. ImageAnal.2020,63,101694.[CrossRef] 21. Lu,D.;Popuri,K.;Ding,G.W.;Balachandar,R.;Beg,M.F.;Weiner,M.;Aisen,P.;Petersen,R.;Jack,C.;Jagust,W.;etal.Multimodal andMultiscaleDeepNeuralNetworksfortheEarlyDiagnosisofAlzheimer’sDiseaseusingstructuralMRandFDG-PETimages. Sci.Rep.2018,8,5697.[CrossRef] 22. Ahmed,S.;Choi,K.Y.;Lee,J.J.;Kim,B.C.;Kwon,G.R.;Lee,K.H.;Jung,H.Y.EnsemblesofPatch-BasedClassifiersforDiagnosisof AlzheimerDiseases.IEEEAccess2019,7,73373-73383.[CrossRef] 23. Jain,R.;Jain,N.;Aggarwal,A.;Hemanth,D.J.ConvolutionalneuralnetworkbasedAlzheimer’sdiseaseclassificationfrom magneticresonancebrainimages.Cogn.Syst.Res.2019,57,147-159.[CrossRef] 24. Pan,D.;Zeng,A.;Jia,L.;Huang,Y.;Frizzell,T.;Song,X.EarlyDetectionofAlzheimer’sDiseaseUsingMagneticResonance Imaging:ANovelApproachCombiningConvolutionalNeuralNetworksandEnsembleLearning.Front.Neurosci.2020,14,259. [CrossRef][PubMed] 25. Murugan,S.;Venkatesan,C.;Sumithra,M.G.;Gao,X.Z.;Elakkiya,B.;Akila,M.;Manoharan,S.DEMNET:ADeepLearning ModelforEarlyDiagnosisofAlzheimerDiseasesandDementiaFromMRImages.IEEEAccess2021,9,90319-90329.[CrossRef] 26. Nawaz,H.;Maqsood,M.;Afzal,S.;Aadil,F.;Mehmood,I.;Rho,S.Adeepfeature-basedreal-timesystemforAlzheimerdisease stagedetection.Multimed.ToolsAppl.2021,80,35789-35807.[CrossRef] 27. Akram,M.W.;Li,G.;Jin,Y.;Chen,X.;Zhu,C.;Ahmad,A.Automaticdetectionofphotovoltaicmoduledefectsininfraredimages withisolatedanddevelop-modeltransferdeeplearning.Sol.Energy2020,198,175-186.[CrossRef] 28. Oyetade,I.S.;Ayeni,J.O.;Ogunde,A.O.;Oguntunde,B.O.;Olowookere,T.A.Hybridizeddeepconvolutionalneuralnetworkand fuzzysupportvectormachinesforbreastcancerdetection.SNComput.Sci.2022,3,58.[CrossRef] 29. Fatima,M.;Khan,M.A.;Shaheen,S.;Almujally,N.A.;Wang,S.-H.B2C3NetF2:Breastcancerclassificationusinganend-to-end deeplearningfeaturefusionandsatinbowerbirdoptimizationcontrolledNewtonRaphsonfeatureselection.CAAITrans.Intell. Technol.2023,8,1374-1390.[CrossRef] 30. Zahoor,S.;Shoaib,U.;Lali,I.U.BreastCancerMammogramsClassificationUsingDeepNeuralNetworkandEntropy-Controlled WhaleOptimizationAlgorithm.Diagnostics2022,12,557.[CrossRef] 31. Baltruschat,I.M.;Nickisch,H.;Grass,M.;Knopp,T.;Saalbach,A.ComparisonofDeepLearningApproachesforMulti-Label ChestX-RayClassification.Sci.Rep.2019,9,6381.[CrossRef] 32. Kang,J.;Gwak,J.EnsembleofInstanceSegmentationModelsforPolypSegmentationinColonoscopyImages.IEEEAccess2019, 7,26440-26447.[CrossRef] 33. Mirjalili,S.;Lewis,A.TheWhaleOptimizationAlgorithm.Adv.Eng.Softw.2016,95,51-67.[CrossRef] Bioengineering2024,11,1076 16of16 34. Nadimi-Shahraki, M.H.; Zamani, H.; Mirjalili, S. Enhanced whale optimization algorithm for medical feature selection: A COVID-19casestudy.Comput.Biol.Med.2022,148,105858.[CrossRef][PubMed] 35. Agrawal,P.;Abutarboush,H.F.;Ganesh,T.;Mohamed,A.W.MetaheuristicAlgorithmsonFeatureSelection:ASurveyofOne DecadeofResearch(2009-2019).IEEEAccess2021,9,26766-26791.[CrossRef] 36. Shukla,A.;Tiwari,R.;Tiwari,S.Alz-ConvNetsforclassificationofAlzheimerdiseaseusingtransferlearningapproach. SN Comput.Sci.2023,4,404.[CrossRef] 37. Mohammed,B.A.;Senan,E.M.;Rassem,T.H.;Makbol,N.M.;Alanazi,A.A.;Al-Mekhlafi,Z.G.;Almurayziq,T.S.;Ghaleb,F.A. Multi-MethodAnalysisofMedicalRecordsandMRIImagesforEarlyDiagnosisofDementiaandAlzheimer’sDiseaseBasedon DeepLearningandHybridMethods.Electronics2021,10,2860.[CrossRef] 38. Acharya, H.; Mehta, R.; Singh, D.K.AlzheimerDiseaseClassificationUsingTransferLearning. InProceedingsofthe2021 5th International Conference on Computing Methodologies and Communication (ICCMC), Erode, India, 8-10 April 2021; pp.1503-1508. 39. El-Latif,A.A.A.;Chelloug,S.A.;Alabdulhafith,M.;Hammad,M.AccuratedetectionofAlzheimer’sdiseaseusinglightweight deeplearningmodelonMRIdata.Diagnostics2023,13,1216.[CrossRef] 40. Loddo,A.;Buttau,S.;DiRuberto,C.DeeplearningbasedpipelinesforAlzheimer’sdiseasediagnosis:Acomparativestudyand anoveldeep-ensemblemethod.Comput.Biol.Med.2022,141,105032.[CrossRef] Disclaimer/Publisher’sNote: Thestatements, opinionsanddatacontainedinallpublicationsaresolelythoseoftheindividual author(s)andcontributor(s)andnotofMDPIand/ortheeditor(s).MDPIand/ortheeditor(s)disclaimresponsibilityforanyinjuryto peopleorpropertyresultingfromanyideas,methods,instructionsorproductsreferredtointhecontent.
